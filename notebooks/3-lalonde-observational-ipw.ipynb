{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyreadr\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"lalonde.RData\"\n",
    "seed = 1234\n",
    "num_trees = None\n",
    "\n",
    "Y = \"re78\"\n",
    "treat = \"treat\"\n",
    "covar = [\n",
    "    \"age\",\n",
    "    \"education\",\n",
    "    \"black\",\n",
    "    \"hispanic\",\n",
    "    \"married\",\n",
    "    \"nodegree\",\n",
    "    \"re74\",\n",
    "    \"re75\",\n",
    "    \"u74\",\n",
    "    \"u75\",\n",
    "]\n",
    "\n",
    "raw = pyreadr.read_r(PATH)\n",
    "# raw.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDW-CPS1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing and propensity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "# ================\n",
    "ldw_co = raw[\"ldw_co\"].copy()\n",
    "ldw_co[\"treat\"] = 1\n",
    "\n",
    "ldw_cps_plus = pd.concat([raw[\"ldw_cps\"], raw[\"ldw_co\"]])\n",
    "\n",
    "data = ldw_cps_plus.copy().reset_index(drop=True)\n",
    "data.reset_index(inplace=True, names=\"row_idx\")\n",
    "\n",
    "# Estimating propensity score\n",
    "# ==========================\n",
    "X = data[covar]\n",
    "y = data[treat]\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=50, max_depth=4, class_weight=\"balanced\", random_state=seed\n",
    ")\n",
    "calib_model = CalibratedClassifierCV(model, cv=3, method=\"isotonic\")\n",
    "calib_model.fit(X, y)\n",
    "\n",
    "data[\"ps\"] = calib_model.predict_proba(X)[:, 1]\n",
    "\n",
    "# model = LogisticRegression(C=1e6, max_iter=1000)\n",
    "# model.fit(X, y)\n",
    "# data['ps'] = model.predict_proba(X)[:, 1]\n",
    "\n",
    "ldw_cps_trim = data[(data[\"ps\"] < 0.9) & (data[\"sample\"].isin([1, 3]))].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16437, 16), (16177, 16))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, ldw_cps_trim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recalculate PS over trimmed data\n",
    "# ================================\n",
    "\n",
    "X = ldw_cps_trim[covar]\n",
    "y = ldw_cps_trim[treat]\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=50, max_depth=4, class_weight=\"balanced\", random_state=seed\n",
    ")\n",
    "calib_model = CalibratedClassifierCV(model, cv=3, method=\"isotonic\")\n",
    "calib_model.fit(X, y)\n",
    "\n",
    "# model = LogisticRegression(C=1e6, max_iter=1000)\n",
    "# model.fit(X, y)\n",
    "\n",
    "ldw_cps_trim[\"propensity_score\"] = calib_model.predict_proba(X)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "**Facure p. 159:** There is also a bias-variance tradeoff when it comes to IPW. In general, the more precise the propensity score model, the lower the bias. However, a very precise model for $e(x)$ will generate a very imprecise effect estimate. This means you have to make your model precise enough to control for the bias, but not too much, or you will run into variance issues.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse probability weighting (IPW)\n",
    "\n",
    "**Facure p. 159:** The more precise you make your model for $e(x)$ [...] you also make positivity less plausible [...] since you will concentrate the treatment in a los $e(x)$ region, far away from the controls and viceversa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-13423.217566097874"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_t = 1 / ldw_cps_trim.query(\"treat==1\")[\"propensity_score\"]\n",
    "weight_nt = 1 / (1 - ldw_cps_trim.query(\"treat==0\")[\"propensity_score\"])\n",
    "\n",
    "treated = ldw_cps_trim.query(\"treat==1\")[Y]\n",
    "ntreated = ldw_cps_trim.query(\"treat==0\")[Y]\n",
    "\n",
    "y_treat = sum(treated * weight_t) / len(ldw_cps_trim)\n",
    "y_ntreat = sum(ntreated * weight_nt) / len(ldw_cps_trim)\n",
    "\n",
    "y_treat - y_ntreat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    185.000000\n",
       "mean      14.399694\n",
       "std       31.324742\n",
       "min        1.920906\n",
       "25%        2.178973\n",
       "50%        3.647998\n",
       "75%        8.549940\n",
       "max      209.206654\n",
       "Name: propensity_score, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(weight_t).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    15992.000000\n",
       "mean         1.009458\n",
       "std          0.049994\n",
       "min          1.000529\n",
       "25%          1.000529\n",
       "50%          1.000811\n",
       "75%          1.007456\n",
       "max          2.085887\n",
       "Name: propensity_score, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(weight_nt).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, we have weights that are too large in the treated group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stabilizing propensity weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1142.896253187655"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_of_t = ldw_cps_trim[\"treat\"].mean()\n",
    "\n",
    "weight_t_stable = p_of_t / ldw_cps_trim.query(\"treat==1\")[\"propensity_score\"]\n",
    "weight_nt_stable = p_of_t / (1 - ldw_cps_trim.query(\"treat==0\")[\"propensity_score\"])\n",
    "\n",
    "treated = ldw_cps_trim.query(\"treat==1\")[Y]\n",
    "ntreated = ldw_cps_trim.query(\"treat==0\")[Y]\n",
    "\n",
    "nt = treated.shape[0]\n",
    "nc = ntreated.shape[0]\n",
    "\n",
    "y_treat = sum(treated * weight_t_stable) / nt\n",
    "y_ntreat = sum(ntreated * weight_nt_stable) / nc\n",
    "\n",
    "y_treat - y_ntreat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
